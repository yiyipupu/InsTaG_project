# 一、文件夹介绍

- evaluation:
  - 用于定量评估InsTaG模型效果
  - 具体操作请见其中 Readme.md
  - 已进行Docker封装
- TFG：
  - 前后端项目实现，已完成模型训练、推理和实时对话功能
  - 这里需要自行配置环境。
  - 具体操作请见其中 前端展示操作文档.md
- 针对模型存在问题的改进
  - 该文件夹内容正如其名
  - 其中的两个py文件替换InsTaG源码中文件即可
- VoiceClone
  - 语音克隆模型已部署于华为云平台
  - 在该文件夹中可以使用联系小组组长范一朴启动服务器进行测试。
  - 可以感受 很有趣的实时对话
  - 具体操作请见其中 实时对话模块.md
- InsTAG服务器操作.md
  - 介绍了如何进行视频训练、合成
  - InsTaG模型部署于华为平台，并进行了Docker封装

#  

# 二、工作量介绍

### 1.时间上

从12月开始，由于课程多数已经结课，因此小组同学能投入大量时间。我们从**12月1日开始到12月24日每天70%**的时间高强度投入。

### 2.内容上

#### 1.本地运行InsTaG代码

学会使用**wsl2**，本机上安装**Ubuntu22.04**，用来运行InsTaG代码。该环境非常难配置，存在很多需要下载的模型，有的无法联网下载，需要自己在**互联网上找资源**。

在本地配置InsTaG运行环境也很艰难。

第一，有三个模块diff-gaussian-rasterization，gridencoder，simple-knn需要自己手动编译，该问题对我们来说比较陌生，但是最终寻找学习解决了该问题。

第二，Basel Face Model 2009这个模型需要去官网做一个验证，但是我们难以通过，在互联网上找到了资源。

第三，一部分数据的处理，需要换一个环境sapiens_lite跑代码，我们也再次部署了环境。虽然也碰上了很多报错。环境不兼容问题，但是最终解决。

第四，还有一部分数据处理，需要使用OpenFace工具来处理，我们再次下载了并学会使用了该工具。

第五，运行InsTaG主体部分时，也存在environment.yml虽然提供了好几个cuda版本下的库版本，但是实际上好几个版本会存在问题。反复尝试几个版本后，经我们验证，确认Ubuntu22.04+CUDA11.7+pytorch1.13.1是可以跑通的。



#### 2.本地运行CosyVoice代码

小组在初期进行了技术调研与对比测试，一开始尝试了openvoice和cosyvoice开源的最新模型，测试后发现cosyvoice在说话节奏、音色模仿的效果更好，所以我们选择cosyvoice作为语音克隆模型。

首先在本地下载cosyvoice代码，根据requirement.txt配置conda环境。下载并部署了CosyVoice2-0.5B 权重，完成了预训练模型的本地加载与初始化测试。

环境配置后开始进行本地的调试，一开始使用的时候遇到了一系列问题，比如胡言乱语、开头吞音，于是小组成员研究了语音克隆模型的架构、官方readme文件以及采用了一些工程技巧，成功解决以上问题，实现了本地上语音克隆的实现。

在此基础上集成了语音识别与大模型client，搭建了实时对话框架。



#### 3.Docker封装InsTaG代码

该部分我们起初尝试通过网络下载的方式配置，但是尝试后发现不可行，该环境过于复杂。通过拷贝环境和代码和模型的方式成功构建镜像。



#### 4.华为云上部署InsTaG

一个账号代金券200元，一般用两天左右就没了，因此会抓紧每一刻来配置。更换了硬件后，环境上又出一些问题，**解决了另一些环境问题**。详细见报告的“问题及解决”部分。

另外**写了api_server.py**，预备和展示用项目进行通信。



#### 5.华为云上部署语音克隆模型

​	为了环境隔离，我们需要将实时对话模块封装为docker，一开始我们的想法是先在本地封装，再部署到华为云。下载各包时需要配置镜像源，有些镜像源失效了要使用vpn下载，封装使用了很长时间。

​	镜像构建成功后，发现由于Windows与Linux底层架构差异，导致docker运行失败。

​	最终我们决定直接在华为云环境进行原生构建，重写Dockerfile，选择合适的服务器，在云端完成最终的Docker部署，配置端口映射与显存资源分配，得到标准的HTTP API接口，本地测试成功。

​	另外，基于该服务写了一个小项目体会实时对话，已提供readme。



#### 6.Docker封装sapiens_lite环境，该环境是一个用于视频数据处理的环境。



#### 7.将sapiens_lite部署于华为云上。



#### 8.Docker封装CosyVoice



#### 9.将语音克隆模型部署于华为云。



#### 10.指标评测部分

我们对所提供的测试数据集均进行处理评估。

该部分源代码提供的指标代码远远不足，不能覆盖到要求的NIQE，PSNR，FID，SSIM，LSE-C，LSE-D，只有PSNR部分的。因此我们查找资料**自己编写了NIQE，PSNR，SSIM，FID部分代码**。并且为这个评测代码**进行Docker封装**。

另外，对于LSE-C,LSE-D指标，我们查阅了https://github.com/Rudrabha/Wav2Lip并且学习使用，成功计算了**LSE-C，LSE-D**。同时对于如何使用进行了讲解。



#### 11.展示前后端部分

- 该部分我们比较有创意地构建了美丽幽默的两套前端模版，并且我们思考了一些有创意的小设置，比如切换“白天黑夜模式”、选择AI聊天风格、提供了两个训练后的模型供使用，一个男性一个女性，可以自由选择。

- 后端部分根据我们的InsTaG模型和语音克隆模型的服务器中api_server.py重新编写了，实现了连接使用。



#### 12.模型改进部分

撰写了模型改进的方案，对InsTaG模型的做了四项关键改进：

1）为运动网络添加时序平滑模块，减少边缘抖动；

2）引入局部刚性约束损失，抑制整体晃动；

3）为球谐光照系数增加时间一致性约束，缓解闪烁；

4）使用鲁棒几何损失，降低噪声传递



# 总结

总的来说我们对于要求的任务**全部完成**。并且额外提供了

- 美丽有特色的两套前端UI
- 对模型所存在的问题进行思考改进
- 一个仅用于实时对话的小项目（这个很有趣）

我们共进行了**5个Docker**封装任务。

- InsTaG环境
- sapiens_lite：一个用于视频数据处理的环境
- instag-eval：用于NIQE，PSNR，FID，SSIM指标评估
- wav2lip-lse：用于LSE-C/LSE-D指标评估
- cosy-voice：语音克隆模型

将**2项服务**部署于服务器：

- 语音克隆模型
- InsTaG人脸合成模型

并为**所有项目提供readme**以便于复现。
